{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhC69GQPjL2b"
      },
      "source": [
        "# Time to slice and dice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96fFNMvKjL2c"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZpiUHddjL2c"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX9FPMn9jL2c"
      },
      "outputs": [],
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
        "!unzip drugsCom_raw.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT9gbMwMjL2c"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\n",
        "# \\t is the tab character in Python\n",
        "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ASbe-DqjL2c"
      },
      "outputs": [],
      "source": [
        "drug_sample = drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "# Print the first few examples of the dataset\n",
        "drug_sample[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVza2jq1jL2d"
      },
      "outputs": [],
      "source": [
        "for split in drug_dataset.keys():\n",
        "    assert len(drug_dataset[split]) == len(drug_dataset[split].unique(\"Unnamed: 0\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1nBtbJxjL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset = drug_dataset.rename_column(\n",
        "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\"\n",
        ")\n",
        "drug_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfo7fSekjL2d"
      },
      "outputs": [],
      "source": [
        "def lowercase_condition(example):\n",
        "    return {\"condition\": example[\"condition\"].lower()}\n",
        "\n",
        "\n",
        "drug_dataset.map(lowercase_condition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ot5R8T9jL2d"
      },
      "outputs": [],
      "source": [
        "def filter_nones(x):\n",
        "    return x[\"condition\"] is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnKqc839jL2d"
      },
      "outputs": [],
      "source": [
        "(lambda x: x * x)(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F5ovA4rjL2d"
      },
      "outputs": [],
      "source": [
        "(lambda base, height: 0.5 * base * height)(4, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RG2oSwnjL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cApfg6KNjL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset = drug_dataset.map(lowercase_condition)\n",
        "# Check that lowercasing worked\n",
        "drug_dataset[\"train\"][\"condition\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-sAyCF0jL2d"
      },
      "outputs": [],
      "source": [
        "def compute_review_length(example):\n",
        "    return {\"review_length\": len(example[\"review\"].split())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3xqaNbEjL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset = drug_dataset.map(compute_review_length)\n",
        "# Inspect the first training example\n",
        "drug_dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOVKNT_3jL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset[\"train\"].sort(\"review_length\")[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJyv773QjL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset = drug_dataset.filter(lambda x: x[\"review_length\"] > 30)\n",
        "print(drug_dataset.num_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5amI95BjL2d"
      },
      "outputs": [],
      "source": [
        "import html\n",
        "\n",
        "text = \"I&#039;m a transformer called BERT\"\n",
        "html.unescape(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRsM-uY1jL2d"
      },
      "outputs": [],
      "source": [
        "drug_dataset = drug_dataset.map(lambda x: {\"review\": html.unescape(x[\"review\"])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSECdgeZjL2d"
      },
      "outputs": [],
      "source": [
        "new_drug_dataset = drug_dataset.map(\n",
        "    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jflNKC5IjL2d"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"review\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAqoHBZFjL2d"
      },
      "outputs": [],
      "source": [
        "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjrrvmtwjL2e"
      },
      "outputs": [],
      "source": [
        "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
        "\n",
        "\n",
        "def slow_tokenize_function(examples):\n",
        "    return slow_tokenizer(examples[\"review\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQttddnzjL2e"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_split(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"review\"],\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_overflowing_tokens=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4iiA6V7jL2e"
      },
      "outputs": [],
      "source": [
        "result = tokenize_and_split(drug_dataset[\"train\"][0])\n",
        "[len(inp) for inp in result[\"input_ids\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7OySKO7jL2e"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHOKOQPgjL2e"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = drug_dataset.map(\n",
        "    tokenize_and_split, batched=True, remove_columns=drug_dataset[\"train\"].column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftDcp1cMjL2e"
      },
      "outputs": [],
      "source": [
        "len(tokenized_dataset[\"train\"]), len(drug_dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVFOKclkjL2e"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_split(examples):\n",
        "    result = tokenizer(\n",
        "        examples[\"review\"],\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_overflowing_tokens=True,\n",
        "    )\n",
        "    # Extract mapping between new and old indices\n",
        "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
        "    for key, values in examples.items():\n",
        "        result[key] = [values[i] for i in sample_map]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjwRcZGTjL2e"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtOwY0dWjL2e"
      },
      "outputs": [],
      "source": [
        "drug_dataset.set_format(\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUL-jQTrjL2e"
      },
      "outputs": [],
      "source": [
        "drug_dataset[\"train\"][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8sgoYQ4jL2e"
      },
      "outputs": [],
      "source": [
        "train_df = drug_dataset[\"train\"][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtcjJkF9jL2e"
      },
      "outputs": [],
      "source": [
        "frequencies = (\n",
        "    train_df[\"condition\"]\n",
        "    .value_counts()\n",
        "    .to_frame()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"index\": \"condition\", \"condition\": \"frequency\"})\n",
        ")\n",
        "frequencies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xlk0w7QjL2e"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "freq_dataset = Dataset.from_pandas(frequencies)\n",
        "freq_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlH_wSYMjL2e"
      },
      "outputs": [],
      "source": [
        "drug_dataset.reset_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHdZnsuVjL2e"
      },
      "outputs": [],
      "source": [
        "drug_dataset_clean = drug_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)\n",
        "# Rename the default \"test\" split to \"validation\"\n",
        "drug_dataset_clean[\"validation\"] = drug_dataset_clean.pop(\"test\")\n",
        "# Add the \"test\" set to our `DatasetDict`\n",
        "drug_dataset_clean[\"test\"] = drug_dataset[\"test\"]\n",
        "drug_dataset_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beHvuzmwjL2e"
      },
      "outputs": [],
      "source": [
        "drug_dataset_clean.save_to_disk(\"drug-reviews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iur9aWv2jL2h"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "drug_dataset_reloaded = load_from_disk(\"drug-reviews\")\n",
        "drug_dataset_reloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sJcTXN1jL2h"
      },
      "outputs": [],
      "source": [
        "for split, dataset in drug_dataset_clean.items():\n",
        "    dataset.to_json(f\"drug-reviews-{split}.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLK7Z1aQjL2h"
      },
      "outputs": [],
      "source": [
        "!head -n 1 drug-reviews-train.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ8FEBkAjL2h"
      },
      "outputs": [],
      "source": [
        "data_files = {\n",
        "    \"train\": \"drug-reviews-train.jsonl\",\n",
        "    \"validation\": \"drug-reviews-validation.jsonl\",\n",
        "    \"test\": \"drug-reviews-test.jsonl\",\n",
        "}\n",
        "drug_dataset_reloaded = load_dataset(\"json\", data_files=data_files)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Time to slice and dice",
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}